[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data & Exploration",
    "section": "",
    "text": "Libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nfrom plotnine import *\n\n\nCustom Functions\n\nimport function as cfun\n\n\nAll custom functions used for the analysis can be found here \n\n\n\n\nData\n\ntrain = pd.read_csv('data/train.csv', parse_dates = ['Datetime'])\n\n\nVariable Definition\nSensor1_PM2.5, Sensor2_PM2.5:: These are recorded PM2.5 from Sensor 1 and Sensor 2.\nTemparature :: This is the degree or indensity of heat present when each PM2.5 was recorded using a Celsius scale. Note that higher tempemperature leads to low air quality. Also When the weather is hot primary sources of pollutants tend to increase.\nRelative_Humidity :: Relative humidity is the amount of water vapor in the air, expressed as a percentage of the maximum amount of water vapor the air can hold at the same temperature. A high humidity increases the rate of harmful or toxic chemicals in the air.\n\n\nData Inspection\n\nData Info\n\ntrain.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 297177 entries, 0 to 297176\nData columns (total 7 columns):\n #   Column             Non-Null Count   Dtype         \n---  ------             --------------   -----         \n 0   ID                 297177 non-null  object        \n 1   Datetime           297177 non-null  datetime64[ns]\n 2   Sensor1_PM2.5      293563 non-null  float64       \n 3   Sensor2_PM2.5      293563 non-null  float64       \n 4   Temperature        293628 non-null  float64       \n 5   Relative_Humidity  293628 non-null  float64       \n 6   Offset_fault       297177 non-null  int64         \ndtypes: datetime64[ns](1), float64(4), int64(1), object(1)\nmemory usage: 15.9+ MB\n\n\nThere are 297,177 records and 7 variables of airquality data in the training data set, also the non null count shows that tamperature, relative humidity and both sensors have missing values in them.\n\n\nMissing Values\n\nna_df = train.isnull().sum().to_frame().rename(columns = {0: \"Number of Missing Value\"})\nna_df[\"percentage\"] = round((na_df[\"Number of Missing Value\"] / train.shape[0])*100, 3)\nna_df\n\n\n\n\n\n  \n    \n      \n      Number of Missing Value\n      percentage\n    \n  \n  \n    \n      ID\n      0\n      0.000\n    \n    \n      Datetime\n      0\n      0.000\n    \n    \n      Sensor1_PM2.5\n      3614\n      1.216\n    \n    \n      Sensor2_PM2.5\n      3614\n      1.216\n    \n    \n      Temperature\n      3549\n      1.194\n    \n    \n      Relative_Humidity\n      3549\n      1.194\n    \n    \n      Offset_fault\n      0\n      0.000\n    \n  \n\n\n\n\nBoth PM2.5 sensor have 3,614 missing values which is 1.2% of the train data set, while both tempaerature and relative humidity have 3,549 (1.2%) of missing data.\n\n\nQuestion:\nThere are similar missing number of values for both sensors and also temperature and relative humidity, so are these missing records similar in the data.\n\ndef related_missing_record(df, cols):\n    check_1 = df.loc[df[cols[0]].isna()].loc[df[cols[1]].notna()].shape[0]\n    check_2 = df.loc[df[cols[1]].isna()].loc[df[cols[0]].notna()].shape[0]\n    return check_1 == check_2\n\nprint(f\"Both Sensor ::\\n{related_missing_record(train, ['Sensor1_PM2.5', 'Sensor2_PM2.5'])}\\n\")\nprint(f\"Train Temperature & Relative Humidity::\\n{related_missing_record(train, ['Temperature', 'Relative_Humidity'])}\\n\")\n\nBoth Sensor ::\nTrue\n\nTrain Temperature & Relative Humidity::\nTrue\n\n\n\nLooks like there were reasons/faliure for skipping data entry during a specific period of time for both sensors. let get the minimum and maximum date for this missing record.\n\nfor col in [\"Sensor1_PM2.5\", \"Temperature\"]:\n    print(f\"{col} ::\\n{train.loc[train[col].isna()]['Datetime'].agg(['min', 'max'])}\\n\")\n\nSensor1_PM2.5 ::\nmin   2021-10-18 10:00:13\nmax   2021-10-22 14:58:43\nName: Datetime, dtype: datetime64[ns]\n\nTemperature ::\nmin   2021-10-30 11:00:31\nmax   2022-01-19 14:59:34\nName: Datetime, dtype: datetime64[ns]\n\n\n\n\n\nOutliers\n\nsns.set_style(\"whitegrid\")\nfig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (10, 6))\nfig.suptitle('Variable Distribution', y = 0.93, fontsize = 16)\n\nfor ax, data, name in zip(axes.flatten(), train, ['Sensor1_PM2.5', 'Sensor2_PM2.5', 'Temperature', 'Relative_Humidity']):\n    sns.boxplot(train[name], ax = ax)\n    ax.set_xlabel(name)\n\n\n\n\n\noutlier_cols = [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\", \"Relative_Humidity\"]\n\nfor col in outlier_cols:\n    print(f\"{col} Outlier :: {cfun.get_outlier(train, col, 1.5)}\")\n    print(\"-\"*20)\n\nSensor1_PM2.5 Outlier :: [-18.055, 89.905]\n--------------------\nSensor2_PM2.5 Outlier :: [-22.555000000000003, 89.64500000000001]\n--------------------\nRelative_Humidity Outlier :: [33.5, 125.5]\n--------------------\n\n\nBoth Sensors have some extrem large values that shows that there where some times when the sensors picked up dengerous level of Fine particulate matter around the area.\n\n\nQuestion:\nAre these extreme values somehow related to the periods when the pm2.5 sensors where condsidered faulty.\n\nfor col in [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\"]:\n    print(f\"{col} Outlier :: {cfun.get_outlier(train.query('Offset_fault == 0'), col, 1.5, typ='upper')}\\n\")\n    print(f\"Max {col} value :: {train.query('Offset_fault == 0')[col].max()}\\n\\n\")\n\nSensor1_PM2.5 Outlier :: 92.72\n\nMax Sensor1_PM2.5 value :: 997.96\n\n\n\n\nSensor2_PM2.5 Outlier :: 92.025\n\nMax Sensor2_PM2.5 value :: 997.26\n\n\n\n\n\nfor col in [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\"]:\n    print(f\"{col} Outlier :: {cfun.get_outlier(train.query('Offset_fault == 1'), col, 1.5, typ='upper')}\\n\")\n    print(f\"Max {col} value :: {train.query('Offset_fault == 1')[col].max()}\\n\\n\")\n\nSensor1_PM2.5 Outlier :: 81.525\n\n\n\nMax Sensor1_PM2.5 value :: 283.18\n\n\nSensor2_PM2.5 Outlier :: 71.0\n\nMax Sensor2_PM2.5 value :: 248.4\n\n\n\n\nBoth occations show that the extreme values are present inspite of whether the sensor is considered faulty or not.\n\nfor col in outlier_cols:\n    print(f\"Number of Outlier in {col} is {cfun.filter_outlier(train, col, 'inner').shape[0]:,}\")\n    print(\"-\"*46)\n\nNumber of Outlier in Sensor1_PM2.5 is 17,402\n----------------------------------------------\n\n\nNumber of Outlier in Sensor2_PM2.5 is 15,463\n----------------------------------------------\n\n\nNumber of Outlier in Relative_Humidity is 772\n----------------------------------------------\n\n\n\n\n\nData Cleaning\nThe train data will be restructured for exploration.\n\ne_train = train.dropna().copy()\ne_train.shape\n\n(290014, 7)\n\n\n\n\n\nExploratory Data Analysis\n\nAdditional Variables\nThe sensors PM2.5 records are numeric, a categorical variable will be created to distinguish this records for better data exploration.\n\ne_train = cfun.add_pmCategory(e_train, ordinal=False)\n\nfor col in [\"S1_AQI\", \"S2_AQI\"]:\n    e_train[col] = e_train[col].astype(\"category\") \n    e_train[col] = e_train[col].cat.reorder_categories([\"Good\", \"Moderate\", \"Unhealthy (SG)\", \"Unhealthy\", \"Very Unhealthy\", \"Hazardous\"], ordered = True)\n\nDefining Air Quality Index Categories:\n1. Good :: Little to no risk (PM2.5 from 0 - 12.0).\n2. Moderate :: Unusually sensitive individuals may experience respiratory symptoms. (PM2.5 from 21.1 - 35.4).\n3. Unhealthy (for sensitive groups) :: Increasing likelihood of respiratory symptoms in sensitive individuals. (PM2.5 from 35.5 - 55.4).\n4. Unhealthy :: Increased respiratory effect in general population. (PM2.5 from 55.5 - 150.4).\n5. Very Unhealthy :: Significant increase in respiratory effect in general population. (PM2.5 from 150.4 - 250.4).\n6. Hazardous :: Serious risk of respiratory effect in general population (PM2.5 from 250.4 - 500.4).\nsource: U.S Environmental Protection Agency\n The Datetime contains the timestamp of the data collection, from this variable the individual hour, month, and year will be extracted.\n\ne_train = cfun.get_standAlone_dates(e_train, \"Datetime\", [\"hour\", \"month\", \"year\"])\n\nChanging offset fault for better readability during exploration.\n\ne_train[\"faulty\"] = e_train[\"Offset_fault\"].replace({0: \"No\", 1: \"Yes\"})\ne_train.head(3)\n\n\n\n\n\n  \n    \n      \n      ID\n      Datetime\n      Sensor1_PM2.5\n      Sensor2_PM2.5\n      Temperature\n      Relative_Humidity\n      Offset_fault\n      S1_AQI\n      S2_AQI\n      Hour\n      Month\n      Year\n      faulty\n    \n  \n  \n    \n      0\n      ID_QF0ZTQJ2SF5Q\n      2021-11-03 04:06:31\n      52.58\n      49.52\n      17.4\n      96.0\n      0\n      Unhealthy (SG)\n      Unhealthy (SG)\n      4\n      11\n      2021\n      No\n    \n    \n      1\n      ID_4GTK689CNX5S\n      2021-11-08 18:43:23\n      35.25\n      33.40\n      25.0\n      75.0\n      0\n      Moderate\n      Moderate\n      18\n      11\n      2021\n      No\n    \n    \n      2\n      ID_DL7VVKW9U7XQ\n      2021-11-07 09:50:33\n      19.18\n      23.50\n      24.9\n      75.0\n      0\n      Moderate\n      Moderate\n      9\n      11\n      2021\n      No\n    \n  \n\n\n\n\n\n\n\nUnivariate Analysis\n\ncfun.rec_count(e_train, \"faulty\", title = \"Device Status\", typ = \"plt\")\n\n\n\n\n<ggplot: (103465133075)>\n\n\nThe outcome variable offset fault contains only two categories which are 1/Yes for PM2.5 sensor that was considered to have been sending faulty signals at the time and 0/No for sensors working well. From the bar chart above, there are less faulty sensors (36.95%) that faulty sensors (63.05%) overall.\n\n\ne_train.select_dtypes(\"number\").describe().applymap(lambda x: round(x, 3))\n\n\n\n\n\n  \n    \n      \n      Sensor1_PM2.5\n      Sensor2_PM2.5\n      Temperature\n      Relative_Humidity\n      Offset_fault\n      Hour\n      Month\n      Year\n    \n  \n  \n    \n      count\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n    \n    \n      mean\n      40.902\n      38.319\n      23.323\n      78.614\n      0.369\n      11.350\n      9.082\n      2021.208\n    \n    \n      std\n      28.598\n      28.723\n      3.842\n      14.792\n      0.483\n      6.969\n      4.195\n      0.406\n    \n    \n      min\n      -9.450\n      -9.700\n      16.700\n      27.000\n      0.000\n      0.000\n      1.000\n      2021.000\n    \n    \n      25%\n      22.570\n      19.620\n      20.400\n      68.000\n      0.000\n      5.000\n      10.000\n      2021.000\n    \n    \n      50%\n      36.650\n      33.850\n      21.900\n      84.000\n      0.000\n      11.000\n      11.000\n      2021.000\n    \n    \n      75%\n      49.550\n      47.700\n      26.300\n      91.000\n      1.000\n      17.000\n      12.000\n      2021.000\n    \n    \n      max\n      997.960\n      997.260\n      34.900\n      99.000\n      1.000\n      23.000\n      12.000\n      2022.000\n    \n  \n\n\n\n\nIn micrograms per cubic meter the minimum value for sensors 1 and 2 falls within the range -9.45 to -9.70 respectively while that maximum value falls within the range 997.96 to 997.26 respectively which shows only a very small difference, for the average value given that there are huge presence of outliers in both sensors it will be more accurate to look at the median value where 50% for sensor 1 fall between 36.65 and lower also for sensor 2 33.85 and lower.\nThere was an average temperature of 23.32 degrees overall for the train set and for relative humidity 78.61.\n\n\nSensor PM2.5 Distribution\n\nSensor 1Sensor 2\n\n\n\ncfun.histPlot(e_train, \"Sensor1_PM2.5\", bins = 100, title=f\"Sensor 1 PM2.5\")\n\n\n\n\n<ggplot: (103462325792)>\n\n\n\n\n\ncfun.histPlot(e_train, \"Sensor2_PM2.5\", bins = 100, title=f\"Sensor 2 PM2.5\")\n\n\n\n\n<ggplot: (103469997618)>\n\n\n\n\n\n\n\nAir Quality Index\n\nSensor 1Sensor 2\n\n\n\ncfun.air_quality_count(e_train, \"S1_AQI\")\n\n\n\n\n<ggplot: (103474331354)>\n\n\n\n\n\ncfun.air_quality_count(e_train, \"S2_AQI\")\n\n\n\n\n<ggplot: (103467692831)>\n\n\n\n\n\nSensor 2 Picked up more Good PM2.5 signals (11.87%) than sensor 1 (8.51%), both sensors have just 0.03% of it recodes as hazadious while the highest Air quality index category recorded was moderate level with 39% and 41% respectively for sensor 1 and 2.\n\n\nTemperature\n\nprint(cfun.boxPlot(e_train, \"Temperature\"))\nprint(cfun.histPlot(e_train, \"Temperature\", bins=35))\n\n\n\n\n\n\n\n\n\n\n\n\n\nGiven that the distibution is skewed, it shows that there are more low temperatures recorded then high temperatures.\n\n\nRelative Humidity\n\nprint(cfun.boxPlot(e_train, \"Relative_Humidity\", axis_text_suffix=\"%\"))\nprint(cfun.histPlot(e_train, \"Relative_Humidity\", bins=35, axis_text_suffix=\"%\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nMore high relative humidity was recorded than low relative humidity Over the selected period.\n\n\n\nDateTime\n\ne_train[\"Datetime\"].describe()\n\ncount                  290014\nunique                 286694\ntop       2021-11-05 12:40:33\nfreq                        3\nfirst     2021-10-15 16:00:31\nlast      2022-01-21 07:34:57\nName: Datetime, dtype: object\n\n\nFor the train data set the we can see that the records started from the 15th of October 2021 up to the 21st of january 2022.\n\nMonth\n\ne_train[\"Month\"].unique()\n\narray([11,  1, 12, 10], dtype=int64)\n\n\n\ncfun.rec_count(e_train, \"Month\", rename_axis_text = [\"January\", \"October\", \"November\", \"December\"])\n\n\n\n\n<ggplot: (103466907288)>\n\n\n\n\nYear\n\ncfun.rec_count(e_train, \"Year\")\n\n\n\n\n<ggplot: (103469877957)>\n\n\n\n\n\n\n\nMultivarite Analysis\n\nDevice Status and Particulate Matter\n\nSensor 1Sensor 2\n\n\n\ncfun.boxPlot(e_train,  num_var=\"Sensor1_PM2.5\", cat_var=\"faulty\",\n            color=[\"#03B4C8\", \"#EE6A50\"],\n            title=[f\"particulate matter 2.5 From Sensor 1\", \"Device Status\"])\n\n\n\n\n<ggplot: (103473763097)>\n\n\n\n\n\ncfun.boxPlot(e_train,  num_var=\"Sensor2_PM2.5\", cat_var=\"faulty\",\n             color=[\"#03B4C8\", \"#EE6A50\"],\n             title=[f\"particulate matter 2.5 From Sensor 2\", \"Device Status\"])\n\n\n\n\n<ggplot: (103467692042)>\n\n\n\n\n\nFor both sensors there are many extreme PM2.5 values recorded when no faulty signals was detected than when it was.\n\nsen_agg = cfun.vars_longer_summary(e_train, \n                                   select_vars = [\"faulty\", \"Sensor1_PM2.5\", \"Sensor2_PM2.5\"], \n                                   var_name = \"Sensor\", value_name = \"PM 2.5\", \n                                   replace_rec = [\"Sensor 1\", \"Sensor 2\"])\n\nsummary_fun = [\"median\", \"max\"]\nplt_title = [\"Median\", \"Maximum\"]\n\nfor sumy_fun, plt_tl in zip(summary_fun, plt_title):\n    print(cfun.facet_summary_plot2(df = sen_agg, cat_var = \"faulty\", num_var = sumy_fun, \n                                  fill = \"faulty\", facet_by = \"Sensor\", \n                                  ylab = \"PM2.5\", \n                                  title = f\"{plt_tl} Particulate Matter By Offset Fault For Each Sensor\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Median PM2.5 for sensor 2 when no signal offset fault was detected (61.93%) is higher than that of sensor 1 (55.31%) and the reverse is the case when a fault was detected. in conclusion sensor 1 had more offset faults than sensor 2.\n\n\nTemperature, Relative Humidity and Device status\n\ntr_agg = cfun.vars_longer_summary(e_train, \n                                  select_vars = [\"faulty\", \"Temperature\", \"Relative_Humidity\"],\n                                  var_name  = \"variable\", value_name = \"value\")\n\ncfun.facet_summary_plot2(\n    df=tr_agg, cat_var=\"faulty\", num_var=\"median\", \n    fill=\"faulty\", facet_by=\"variable\", scales=\"free_y\", \n    sb_aj=0.1, title=\"Median Of Temperature & Relative Humidity By Device Status\")                                 \n\n\n\n\n<ggplot: (103460835782)>\n\n\n\n\nAir Quality with Temperature & Relative Humidity\n\nSensor 1Sensor 2\n\n\n\naqi_tr =  cfun.vars_longer_summary(e_train, \n                                   select_vars=[\"S1_AQI\", \"Temperature\", \"Relative_Humidity\"], \n                                   var_name   =\"Variable\", \n                                   value_name =\"PM2.5\")\n\ncfun.facet_summary_plot(\n    aqi_tr, \"S1_AQI\", \"mean\", \"Variable\", \n    sb_aj=0.06, \n    title=\"Average Relative Humidity & Temperature For Sensor 1 By Air Quality Index\")\n\n\n\n\n<ggplot: (103469961883)>\n\n\n\n\n\naqi_tr =  cfun.vars_longer_summary(e_train, \n                                   select_vars=[\"S2_AQI\", \"Temperature\", \"Relative_Humidity\"], \n                                   var_name   =\"Variable\", \n                                   value_name =\"PM2.5\")\n\ncfun.facet_summary_plot(\n    aqi_tr, \"S2_AQI\", \"mean\", \"Variable\", \n    sb_aj=0.06, \n    title=\"Average Relative Humidity & Temperature For Sensor 2 By Air Quality Index\"\n    )                                   \n\n\n\n\n<ggplot: (103347821319)>\n\n\n\n\n\nFor relative humidity using the above chart the higher the critical level of PM2.5 the higher the relative humidity on an average with the exception of hazardous level. while for temperature the higher the critical level of PM2.5 the lower the degree of temperature on an average with only the exception of hazardous level.\n\n\nCorrelation\n\nplt.figure(figsize = (20, 6))\nnum_cols = ['Sensor1_PM2.5', 'Sensor2_PM2.5', 'Temperature', 'Relative_Humidity']\nsns.pairplot(e_train[num_cols], \n             kind=\"scatter\", \n             plot_kws=dict(s=80, edgecolor=\"white\", linewidth=2.5, color=\"#02A9EA\"))\nplt.show()\n\n<Figure size 1920x576 with 0 Axes>\n\n\n\n\n\n\n# Ordinal Encoding\ncorr_df = e_train.copy()\n\nfor col in [\"S1_AQI\", \"S2_AQI\"]:\n    corr_df[col] = corr_df[col].replace({\"Hazardous\"     : 0, \n                                         \"Very Unhealthy\": 1, \n                                         \"Unhealthy\"     : 2, \n                                         \"Unhealthy (SG)\": 3, \n                                         \"Moderate\"      : 4, \n                                         \"Good\"          : 5})\n    corr_df[col] = corr_df[col].astype(\"int64\")\n\ncor = corr_df.select_dtypes([\"int64\", \"float64\"]).corr()\n\nplt.figure(figsize = (10, 8))\nsns.heatmap(cor, cmap = 'RdYlBu', annot = True, center = 0)\nplt.title('Correlogram', fontsize = 15, color = 'darkgreen')\nplt.show()\n\n\n\n\nBoth sensors 1 & 2 are highly (positive) correlated with each other.\nAir quality index(AQI) from both sensors are negatively correlated with the PM2.5 values.\nTemperature have a positive correlation with AQI while Relative Humidity have a negative correlation with AQI."
  },
  {
    "objectID": "pm_notebook.html",
    "href": "pm_notebook.html",
    "title": "PM2.5 Sensor Offset Fault Prediction",
    "section": "",
    "text": "Libraries\nData\nData Dictionary\nData Inspection\nData Cleaning\nExplortatory Data Analysis\nModelling\nTesting\n\n ## Libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nfrom plotnine import *\n\nfrom sklearn.model_selection import KFold, cross_validate, cross_val_score, cross_val_predict  # train_test_split,\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import KNNImputer\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score\n\n\n# Custom Functions\nimport function as cfun\n\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n ## Data\n\ntrain = pd.read_csv('data/train.csv', parse_dates = ['Datetime'])\ntest = pd.read_csv('data/test.csv', parse_dates = ['Datetime'])\nsamplesubmission = pd.read_csv('data/SampleSubmission.csv')\n\n ### Data Dictionary\nSensor1_PM2.5, Sensor2_PM2.5 :: These are recorded PM2.5 from Sensor 1 and Sensor 2.\nNOTE : PM2.5 also called Fine particulate matter are tiny particles in the air that reduce visibility and cause the air to appear hazy when levels are elevated. (PM2.5 are complex because they can be made up of numerous types of chemicals and particles and they can also be partly liquid. measured in micrograms per cubic meter. “a microgram is a unit of weight, there are a million micrograms in a gram, & a pound = 450 grams.”\nTemparature :: This is the degree or indensity of heat present when each PM2.5 was recorded using a Celsius scale. Note that higher tempemperature leads to low air quality. Also When the weather is hot primary sources of pollutants tend to increase.\nRelative_Humidity :: Relative humidity is the amount of water vapor in the air, expressed as a percentage of the maximum amount of water vapor the air can hold at the same temperature. A high humidity increases the rate of harmful or toxic chemicals in the air.\n ### Data Inspection 1. Data Info 2. Missing Values 3. Duplicates 4. Outliers\n #### Data Info\n\ntrain.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 297177 entries, 0 to 297176\nData columns (total 7 columns):\n #   Column             Non-Null Count   Dtype         \n---  ------             --------------   -----         \n 0   ID                 297177 non-null  object        \n 1   Datetime           297177 non-null  datetime64[ns]\n 2   Sensor1_PM2.5      293563 non-null  float64       \n 3   Sensor2_PM2.5      293563 non-null  float64       \n 4   Temperature        293628 non-null  float64       \n 5   Relative_Humidity  293628 non-null  float64       \n 6   Offset_fault       297177 non-null  int64         \ndtypes: datetime64[ns](1), float64(4), int64(1), object(1)\nmemory usage: 15.9+ MB\n\n\nThere are 297,177 records and 7 variables of airquality data in the training data set, also the non null count shows that tamperature, relative humidity and both sensors have missing values in them.\n #### Missing Values\n\nna_df = train.isnull().sum().to_frame().rename(columns = {0: \"Number of Missing Value\"})\nna_df[\"percentage\"] = round((na_df[\"Number of Missing Value\"] / train.shape[0])*100, 3)\nna_df\n\n\n\n\n\n  \n    \n      \n      Number of Missing Value\n      percentage\n    \n  \n  \n    \n      ID\n      0\n      0.000\n    \n    \n      Datetime\n      0\n      0.000\n    \n    \n      Sensor1_PM2.5\n      3614\n      1.216\n    \n    \n      Sensor2_PM2.5\n      3614\n      1.216\n    \n    \n      Temperature\n      3549\n      1.194\n    \n    \n      Relative_Humidity\n      3549\n      1.194\n    \n    \n      Offset_fault\n      0\n      0.000\n    \n  \n\n\n\n\nBoth PM2.5 sensors have 3,614 missing values which is 1.2% of the train data set, while both tempaerature and relative humidity have 3,549 (1.2%) of missing data.\n\n\nThere are similar missing number of values for both sensors and also temperature and relative humidity, so are these missing records similar in the data.\n\ndef related_missing_record(df, cols):\n    check_1 = df.loc[df[cols[0]].isna()].loc[df[cols[1]].notna()].shape[0]\n    check_2 = df.loc[df[cols[1]].isna()].loc[df[cols[0]].notna()].shape[0]\n    return check_1 == check_2\n\n\nprint(f\"Both Sensor ::\\n{related_missing_record(train, ['Sensor1_PM2.5', 'Sensor2_PM2.5'])}\\n\")\nprint(f\"Train Temperature & Relative Humidity::\\n{related_missing_record(train, ['Temperature', 'Relative_Humidity'])}\\n\")\n\nBoth Sensor ::\nTrue\n\nTrain Temperature & Relative Humidity::\nTrue\n\n\n\nLooks like there were faliure/reason for skipping data entry during a specific period of time for both sensors. let get the minimum and maximum date for this missing record.\n\nfor col in [\"Sensor1_PM2.5\", \"Temperature\"]:\n    print(f\"{col} ::\\n{train.loc[train[col].isna()]['Datetime'].agg(['min', 'max'])}\\n\")\n\nSensor1_PM2.5 ::\nmin   2021-10-18 10:00:13\nmax   2021-10-22 14:58:43\nName: Datetime, dtype: datetime64[ns]\n\nTemperature ::\nmin   2021-10-30 11:00:31\nmax   2022-01-19 14:59:34\nName: Datetime, dtype: datetime64[ns]\n\n\n\n #### Duplicates\n\ntrain.duplicated().sum()\n\n0\n\n\n #### Outliers\n\nsns.set_style(\"whitegrid\")\nfig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (19, 7))\nfig.suptitle('Variable Distribution', y = 0.93, fontsize = 16)\n\nfor ax, data, name in zip(axes.flatten(), train, ['Sensor1_PM2.5', 'Sensor2_PM2.5', 'Temperature', 'Relative_Humidity']):\n    sns.boxplot(train[name], ax = ax)\n    plt.ylabel(name)\n        \n\n\n\n\n\noutlier_cols = [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\", \"Relative_Humidity\"]\nfor col in outlier_cols:\n    print(f\"{col} Outlier :: {cfun.get_outlier(train, col, 1.5)}\")\n    print(\"-\"*20)\n\nSensor1_PM2.5 Outlier :: [-18.055, 89.905]\n--------------------\nSensor2_PM2.5 Outlier :: [-22.555000000000003, 89.64500000000001]\n--------------------\nRelative_Humidity Outlier :: [33.5, 125.5]\n--------------------\n\n\nBoth Sensors have some extrem large values that shows that there where some times when the sensors picked up dengerous level of Fine particulate matter around the area.\n\n\n\nAre these extreme values somehow related to the periods when the pm2.5 sensors where condsidered faulty.\n\nfor col in [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\"]:\n    print(f\"{col} Outlier :: {cfun.get_outlier(train.query('Offset_fault == 0'), col, 1.5, typ='upper')}\\n\")\n    print(f\"Max {col} value :: {train.query('Offset_fault == 0')[col].max()}\\n\\n\")\n\nSensor1_PM2.5 Outlier :: 92.72\n\nMax Sensor1_PM2.5 value :: 997.96\n\n\nSensor2_PM2.5 Outlier :: 92.025\n\nMax Sensor2_PM2.5 value :: 997.26\n\n\n\n\n\nfor col in [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\"]:\n    print(f\"{col} Outlier :: {cfun.get_outlier(train.query('Offset_fault == 1'), col, 1.5, typ='upper')}\\n\")\n    print(f\"Max {col} value :: {train.query('Offset_fault == 1')[col].max()}\\n\\n\")\n\nSensor1_PM2.5 Outlier :: 81.525\n\nMax Sensor1_PM2.5 value :: 283.18\n\n\nSensor2_PM2.5 Outlier :: 71.0\n\nMax Sensor2_PM2.5 value :: 248.4\n\n\n\n\nBoth occations show that the extreme values are present inspite of whether the sensor is considered faulty or not.\n\nfor col in outlier_cols:\n    print(f\"Number of Outlier in {col} is {cfun.filter_outlier(train, col, 'inner').shape[0]:,}\")\n    print(\"-\"*46)\n\nNumber of Outlier in Sensor1_PM2.5 is 17,402\n----------------------------------------------\nNumber of Outlier in Sensor2_PM2.5 is 15,463\n----------------------------------------------\nNumber of Outlier in Relative_Humidity is 772\n----------------------------------------------\n\n\n ### Data Cleaning The train data will be restructured for exploration.\n\n# Dropping missing values\ne_train = train.dropna().copy()\ne_train.shape\n\n(290014, 7)\n\n\n ## Exploratory Data Analysis 1. Additional Variables 1. Univariate Analysis 2. Multivarite Analysis 3. Correlation\n ### Additional Variables\nThe sensors PM2.5 records are numeric, a categorical variable will be created to distinguish this records for better data exploration.\n\ne_train = cfun.add_pmCategory(e_train, ordinal=False)\n\nfor col in [\"S1_AQI\", \"S2_AQI\"]:\n    e_train[col] = e_train[col].astype(\"category\") \n    e_train[col] = e_train[col].cat.reorder_categories([\"Good\", \"Moderate\", \"Unhealthy (SG)\", \"Unhealthy\", \"Very Unhealthy\", \"Hazardous\"], ordered = True)\n\nDefining Air Quality Index Categories 1. Good :: Little to no risk (PM2.5 from 0 - 12.0)\n2. Moderate :: Unusually sensitive individuals may experience respiratory symptoms. (PM2.5 from 21.1 - 35.4)\n3. Unhealthy (for sensitive groups) :: Increasing likelihood of respiratory symptoms in sensitive individuals. (PM2.5 from 35.5 - 55.4) 4. Unhealthy :: Increased respiratory effect in general population. (PM2.5 from 55.5 - 150.4) 5. Very Unhealthy :: Significant increase in respiratory effect in general population. (PM2.5 from 150.4 - 250.4) 6. Hazardous :: Serious risk of respiratory effect in general population (PM2.5 from 250.4 - 500.4)\nsource: U.S.Environmental Protection Agency\nThe Datetime contains the timestamp of the data collection, from this variable the individual hour, month, and year will be extracted.\n\ne_train = cfun.get_standAlone_dates(e_train, \"Datetime\", [\"hour\", \"month\", \"year\"])\n\nChanging offset fault for better readability during exploration\n\ne_train[\"faulty\"] = e_train[\"Offset_fault\"].replace({0: \"No\", 1: \"Yes\"})\ne_train.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Datetime\n      Sensor1_PM2.5\n      Sensor2_PM2.5\n      Temperature\n      Relative_Humidity\n      Offset_fault\n      S1_AQI\n      S2_AQI\n      Hour\n      Month\n      Year\n      faulty\n    \n  \n  \n    \n      0\n      ID_QF0ZTQJ2SF5Q\n      2021-11-03 04:06:31\n      52.58\n      49.52\n      17.4\n      96.0\n      0\n      Unhealthy (SG)\n      Unhealthy (SG)\n      4\n      11\n      2021\n      No\n    \n    \n      1\n      ID_4GTK689CNX5S\n      2021-11-08 18:43:23\n      35.25\n      33.40\n      25.0\n      75.0\n      0\n      Moderate\n      Moderate\n      18\n      11\n      2021\n      No\n    \n    \n      2\n      ID_DL7VVKW9U7XQ\n      2021-11-07 09:50:33\n      19.18\n      23.50\n      24.9\n      75.0\n      0\n      Moderate\n      Moderate\n      9\n      11\n      2021\n      No\n    \n    \n      3\n      ID_6XQOMBXM2DG3\n      2022-01-01 18:55:15\n      19.40\n      15.48\n      24.9\n      70.0\n      0\n      Moderate\n      Moderate\n      18\n      1\n      2022\n      No\n    \n    \n      4\n      ID_UQZW9ISJY9QE\n      2021-11-05 22:23:48\n      38.30\n      34.77\n      20.9\n      89.0\n      0\n      Unhealthy (SG)\n      Moderate\n      22\n      11\n      2021\n      No\n    \n  \n\n\n\n\n ### Univariate Analysis\n\ncfun.rec_count(e_train, \"faulty\", title = \"Device Status\", typ = \"plt\")\n\n\n\n\n<ggplot: (80869490214)>\n\n\nThe outcome variable offset fault contains only two categories which are 1/Yes for PM2.5 sensors that were considered sending faulty signals at the time and 0/No for sensors working well. From the bar chart above, there are less faulty sensors (36.95%) that faulty sensors (63.05%) overall.\n\ne_train.select_dtypes(\"number\").describe().applymap(lambda x: round(x, 3))\n\n\n\n\n\n  \n    \n      \n      Sensor1_PM2.5\n      Sensor2_PM2.5\n      Temperature\n      Relative_Humidity\n      Offset_fault\n      Hour\n      Month\n      Year\n    \n  \n  \n    \n      count\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n      290014.000\n    \n    \n      mean\n      40.902\n      38.319\n      23.323\n      78.614\n      0.369\n      11.350\n      9.082\n      2021.208\n    \n    \n      std\n      28.598\n      28.723\n      3.842\n      14.792\n      0.483\n      6.969\n      4.195\n      0.406\n    \n    \n      min\n      -9.450\n      -9.700\n      16.700\n      27.000\n      0.000\n      0.000\n      1.000\n      2021.000\n    \n    \n      25%\n      22.570\n      19.620\n      20.400\n      68.000\n      0.000\n      5.000\n      10.000\n      2021.000\n    \n    \n      50%\n      36.650\n      33.850\n      21.900\n      84.000\n      0.000\n      11.000\n      11.000\n      2021.000\n    \n    \n      75%\n      49.550\n      47.700\n      26.300\n      91.000\n      1.000\n      17.000\n      12.000\n      2021.000\n    \n    \n      max\n      997.960\n      997.260\n      34.900\n      99.000\n      1.000\n      23.000\n      12.000\n      2022.000\n    \n  \n\n\n\n\nIn micrograms per cubic meter the minimum value for sensors 1 and 2 falls within the range -9.45 to -9.70 respectively while that maximum value falls within the range 997.96 to 997.26 respectively which shows only a very small difference, for the average value given that there are huge presence of outliers in both sensors it will be more accurate to look at the median value where 50% for sensor 1 fall between 36.65 and lower also for sensor 2 33.85 and lower.\nThere was an average temperature of 23.32 degrees overall for the train set and for relative humidity 78.61.\n\n\n\n\nfor col, sensor in zip([\"Sensor1_PM2.5\", \"Sensor2_PM2.5\"], [1, 2]):\n    print(cfun.histPlot(e_train, col, bins = 100, title=f\"Sensor {sensor} PM2.5\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor col in [\"S1_AQI\", \"S2_AQI\"]:\n    print(cfun.air_quality_count(e_train, col))\n\n\n\n\n\n\n\n\n\n\n\n\n\nSensor 2 Picked up more Good PM2.5 signals (11.87%) than sensor 1 (8.51%), both sensors have just 0.03% of it recodes as hazadious while the highest Air quality index category recorded was moderate level with 39% and 41% respectively for sensor 1 and 2.\n\n\n\n\nprint(cfun.boxPlot(e_train, \"Temperature\"))\ncfun.histPlot(e_train, \"Temperature\", bins=35)\n\n\n\n\n\n\n\n\n\n\n<ggplot: (80869548762)>\n\n\nGiven that the distibution is skewed, it shows that there are more low temperatures recorded then high temperatures.\n\n\n\n\nprint(cfun.boxPlot(e_train, \"Relative_Humidity\", axis_text_suffix=\"%\"))\ncfun.histPlot(e_train, \"Relative_Humidity\", bins=35, axis_text_suffix=\"%\")\n\n\n\n\n\n\n\n\n\n\n<ggplot: (80873476733)>\n\n\nMore high relative humidity was recorded than low relative humidity Over the selected period.\n\n\n\n\ne_train[\"Datetime\"].describe()\n\ncount                  290014\nunique                 286694\ntop       2021-11-05 12:40:33\nfreq                        3\nfirst     2021-10-15 16:00:31\nlast      2022-01-21 07:34:57\nName: Datetime, dtype: object\n\n\nFor the train data set the we can see that the records started from the 15th of October 2021 up to the 21st of january 2022.\n\n\n\ne_train[\"Month\"].unique()\n\narray([11,  1, 12, 10], dtype=int64)\n\n\n\ncfun.rec_count(e_train, \"Month\", rename_axis_text = [\"January\", \"October\", \"November\", \"December\"])\n\n\n\n\n<ggplot: (80873454565)>\n\n\n\n\n\n\ncfun.rec_count(e_train, \"Year\")\n\n\n\n\n<ggplot: (80878660783)>\n\n\n ### Multivarite Analysis 1. Device Status and Particulate Matter 2. Temperature, Relative_Humidity and Device status 3. Air Quality with Temperature & Relative Humidity\n #### Device Status and Particulate Matter\n\nf_color = [\"#75F4F4\", \"#D17B83\"]\ncols = [\"Sensor1_PM2.5\", \"Sensor2_PM2.5\"]\ns_type = [1, 2]\n\nfor sensor, typ in zip(cols, s_type):\n    print(cfun.boxPlot(e_train, \n                       num_var = sensor, \n                       cat_var = \"faulty\",\n                       color = f_color,\n#                        zoom = (0, 100),\n                       title = [f\"particulate matter 2.5 From Sensor {typ}\", \"Device Status\"]))\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor both sensors there where more extreme PM2.5 values recorded when no faulty signals was detected than when it was.\n\nsen_agg = cfun.vars_longer_summary(e_train, \n                                   select_vars = [\"faulty\", \"Sensor1_PM2.5\", \"Sensor2_PM2.5\"], \n                                   var_name = \"Sensor\", value_name = \"PM 2.5\", \n                                   replace_rec = [\"Sensor 1\", \"Sensor 2\"])\nsen_agg.drop(\"sum\", axis=1)\n\n\n\n\n\n  \n    \n      \n      faulty\n      Sensor\n      min\n      mean\n      median\n      max\n    \n  \n  \n    \n      0\n      No\n      Sensor 1\n      0.00\n      44.757375\n      39.58\n      997.96\n    \n    \n      1\n      No\n      Sensor 2\n      0.18\n      45.115641\n      39.73\n      997.26\n    \n    \n      2\n      Yes\n      Sensor 1\n      -9.45\n      34.322565\n      31.98\n      283.18\n    \n    \n      3\n      Yes\n      Sensor 2\n      -9.70\n      26.719856\n      24.42\n      248.40\n    \n  \n\n\n\n\n\nsummary_fun = [\"median\", \"max\"]\nplt_title = [\"Median\", \"Maximum\"]\n\nfor sumy_fun, plt_tl in zip(summary_fun, plt_title):\n    print(cfun.facet_summary_plot2(df = sen_agg, cat_var = \"faulty\", num_var = sumy_fun, fill = \"faulty\", facet_by = \"Sensor\",\n                                   ylab = \"PM2.5\", title = f\"{plt_tl} Particulate Matter By Offset Fault For Each Sensor\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Median PM2.5 for sensor 2 when no signal offset fault was detected (61.93%) is higher than that of sensor 1 (55.31%) and the reverse is the case when a fault was detected. in conclusion sensor 1 had more offset faults than sensor 2.\n\n\n\n\ntr_agg = cfun.vars_longer_summary(e_train, \n                                  select_vars = [\"faulty\", \"Temperature\", \"Relative_Humidity\"],\n                                  var_name  = \"variable\", value_name = \"value\")\ntr_agg.drop(\"sum\", axis=1)\n\n\n\n\n\n  \n    \n      \n      faulty\n      variable\n      min\n      mean\n      median\n      max\n    \n  \n  \n    \n      0\n      No\n      Relative_Humidity\n      27.0\n      78.639955\n      84.0\n      99.0\n    \n    \n      1\n      No\n      Temperature\n      16.7\n      23.314492\n      21.9\n      34.9\n    \n    \n      2\n      Yes\n      Relative_Humidity\n      27.0\n      78.570774\n      84.0\n      99.0\n    \n    \n      3\n      Yes\n      Temperature\n      16.7\n      23.336810\n      22.0\n      34.9\n    \n  \n\n\n\n\n\ncfun.facet_summary_plot2(df = tr_agg, cat_var = \"faulty\", num_var = \"median\", fill = \"faulty\", facet_by = \"variable\", scales = \"free_y\", \n                         sb_aj=0.1, title = \"Median Of Temperature & Relative Humidity By Device Status\")\n\n\n\n\n<ggplot: (80880517760)>\n\n\n #### Air Quality with Temperature & Relative Humidity\n\n\n\n\naqi_tr =  cfun.vars_longer_summary(e_train, \n                                   select_vars=[\"S1_AQI\", \"Temperature\", \"Relative_Humidity\"], \n                                   var_name   =\"Variable\", \n                                   value_name =\"PM2.5\")\naqi_tr.drop(\"sum\", axis=1).head(5)\n\n\n\n\n\n  \n    \n      \n      S1_AQI\n      Variable\n      min\n      mean\n      median\n      max\n    \n  \n  \n    \n      0\n      Good\n      Relative_Humidity\n      27.0\n      65.902633\n      65.0\n      99.0\n    \n    \n      1\n      Good\n      Temperature\n      17.2\n      26.907975\n      27.6\n      34.9\n    \n    \n      2\n      Moderate\n      Relative_Humidity\n      27.0\n      73.571333\n      74.0\n      99.0\n    \n    \n      3\n      Moderate\n      Temperature\n      17.1\n      24.767452\n      24.9\n      34.9\n    \n    \n      4\n      Unhealthy (SG)\n      Relative_Humidity\n      34.0\n      83.586812\n      87.0\n      99.0\n    \n  \n\n\n\n\n\ncfun.facet_summary_plot(aqi_tr, \"S1_AQI\", \"mean\", \"Variable\",\n# colors=[\"#A9DEF9\", \"#F9DEC9\"], # F1AB86\n sb_aj=0.06, title=\"Average Relative Humidity & Temperature For Sensor 1 By Air Quality Index\")\n\n\n\n\n<ggplot: (110011157781)>\n\n\n\n\n\n\naqi_tr =  cfun.vars_longer_summary(e_train, \n                                   select_vars=[\"S2_AQI\", \"Temperature\", \"Relative_Humidity\"], \n                                   var_name   =\"Variable\", \n                                   value_name =\"PM2.5\")\naqi_tr.drop(\"sum\", axis=1).head(5)\n\n\n\n\n\n  \n    \n      \n      S2_AQI\n      Variable\n      min\n      mean\n      median\n      max\n    \n  \n  \n    \n      0\n      Good\n      Relative_Humidity\n      27.0\n      66.620695\n      65.0\n      99.0\n    \n    \n      1\n      Good\n      Temperature\n      17.2\n      26.722606\n      27.5\n      34.9\n    \n    \n      2\n      Moderate\n      Relative_Humidity\n      27.0\n      75.574615\n      78.0\n      99.0\n    \n    \n      3\n      Moderate\n      Temperature\n      16.9\n      24.209235\n      23.5\n      34.9\n    \n    \n      4\n      Unhealthy (SG)\n      Relative_Humidity\n      34.0\n      83.600160\n      87.0\n      99.0\n    \n  \n\n\n\n\n\ncfun.facet_summary_plot(aqi_tr, \"S2_AQI\", \"mean\", \"Variable\", sb_aj=0.06, title=\"Average Relative Humidity & Temperature For Sensor 2 By Air Quality Index\")\n\n\n\n\n<ggplot: (80881608356)>\n\n\nFor relative humidity using the above chart the higher the critical level of PM2.5 the higher the relative humidity on an average with the exception of hazardous level. while for temperature the higher the critical level of PM2.5 the lower the degree of temperature on an average with only the exception of hazardous level.\n ### Correlation\n\nplt.figure(figsize = (27, 12))\nnum_cols = ['Sensor1_PM2.5', 'Sensor2_PM2.5', 'Temperature', 'Relative_Humidity']\nsns.pairplot(e_train[num_cols], kind = \"scatter\", plot_kws = dict(s=80, edgecolor=\"white\", linewidth=2.5, color=\"#02A9EA\"))\nplt.show()\n\n<Figure size 2700x1200 with 0 Axes>\n\n\n\n\n\n\n# Ordinal Encoding\ncorr_df = e_train.copy()\n\nfor col in [\"S1_AQI\", \"S2_AQI\"]:\n    corr_df[col] = corr_df[col].replace({\"Hazardous\"     : 0, \n                                         \"Very Unhealthy\": 1, \n                                         \"Unhealthy\"     : 2, \n                                         \"Unhealthy (SG)\": 3, \n                                         \"Moderate\"      : 4, \n                                         \"Good\"          : 5})\n    corr_df[col] = corr_df[col].astype(\"int64\")\n\n\ncor = corr_df.select_dtypes([\"int64\", \"float64\"]).corr()\n\nplt.figure(figsize = (13, 8))\nsns.heatmap(cor, cmap = 'RdYlBu', annot = True, center = 0)\nplt.title('Correlogram', fontsize = 15, color = 'darkgreen')\nplt.show()\n\n\n\n\nBoth sensors 1 & 2 are highly positively correlated with each other.\nAir quality index(AQI) from both sensors are negatively correlated with the PM2.5 values.\nTemperature have a positive correlation with AQI while Relative Humidity have a negative correlation with AQI.\n ## Modelling\nFor the training set all missing values will be removed from the data.\nAdditional variables such as an ordinal air quality index as integer for both sensors will be added to the training set.\nAlso the hour and day of the year will be extracted from the datetime variable after which the datetime variable will be dropped with the Id variable as they are both high cardinality features.\n\nord_train = train.sort_values(by=\"Datetime\")\n\nadd_df = cfun.add_attributes(ord_train, drop_nan_value=True, fill_nan_value=False)\n\ntrain_c = add_df.drop_missing_value()\ntrain_c = add_df.add_air_quality_index()\ntrain_c = add_df.add_period_variables(hour=True, dayofyear=True)\ntrain_c = train_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\n\ntrain_c.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 290014 entries, 116880 to 226302\nData columns (total 9 columns):\n #   Column             Non-Null Count   Dtype  \n---  ------             --------------   -----  \n 0   Sensor1_PM2.5      290014 non-null  float64\n 1   Sensor2_PM2.5      290014 non-null  float64\n 2   Temperature        290014 non-null  float64\n 3   Relative_Humidity  290014 non-null  float64\n 4   Offset_fault       290014 non-null  int64  \n 5   S1_AQI             290014 non-null  int64  \n 6   S2_AQI             290014 non-null  int64  \n 7   Hour               290014 non-null  int64  \n 8   Day_Of_Year        290014 non-null  int64  \ndtypes: float64(4), int64(5)\nmemory usage: 22.1 MB\n\n\n\noutcome = \"Offset_fault\"\nX = train_c.drop(outcome, axis = 1)\ny = train_c[outcome]\n\nfeature_names = list(train_c.drop(outcome, axis = 1).columns)\n\n\nnum_features = list(X.select_dtypes(\"number\").columns)\nnum_pipeline = Pipeline([\n    (\"std_scaler\", StandardScaler())\n])\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_features)\n])\n\nX = full_pipeline.fit_transform(X)\n\n\n# Transformed X\nX\n\narray([[-1.10957703, -1.01101351,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       [-1.08300205, -0.94242651,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       [-1.20189013, -1.22443398,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       ...,\n       [ 0.11881666,  0.48919661, -1.67174045, ..., -0.52823302,\n        -0.62421669, -1.84915195],\n       [ 0.27721755,  0.2761243 , -1.67174045, ..., -0.52823302,\n        -0.62421669, -1.84915195],\n       [-0.01650596, -0.22243706, -1.67174045, ...,  0.56632168,\n        -0.62421669, -1.84915195]])\n\n\n\ndef cross_validation(model, x=X, y=y, model_name=\"model\", cv=5):\n    y_pred = cross_val_predict(model, x, y, cv=cv, n_jobs=-1) \n        \n    print(f\"{model_name}\\n{'='*50}\")\n    \n    print(f\"Confusion Matrix ::-\\n{confusion_matrix(y, y_pred)}\")\n    print(50*\"-\",\"\\n\")\n    print(f\"Accuracy :: {accuracy_score(y, y_pred)}\\n\")\n    print(classification_report(y, y_pred))\n\n\nlog_reg = LogisticRegression(random_state=11)\ndt_class = DecisionTreeClassifier(random_state=11)\nrf_class = RandomForestClassifier(random_state=11, n_jobs=-1)\nknn_class = KNeighborsClassifier(n_jobs=-1)\n\nmodel = [log_reg, dt_class, rf_class, knn_class]\nmodel_names = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"K-Neighbors\"]\n\n\nfor mdl, mdl_name in zip(model, model_names):\n    cross_validation(mdl, model_name=mdl_name)\n    print(\"\\n\\n\")\n\nLogistic Regression\n==================================================\nConfusion Matrix ::-\n[[171446  11417]\n [ 25463  81688]]\n-------------------------------------------------- \n\nAccuracy :: 0.8728337252684353\n\n              precision    recall  f1-score   support\n\n           0       0.87      0.94      0.90    182863\n           1       0.88      0.76      0.82    107151\n\n    accuracy                           0.87    290014\n   macro avg       0.87      0.85      0.86    290014\nweighted avg       0.87      0.87      0.87    290014\n\n\n\n\nDecision Tree\n==================================================\nConfusion Matrix ::-\n[[162400  20463]\n [ 19569  87582]]\n-------------------------------------------------- \n\nAccuracy :: 0.8619652844345446\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89    182863\n           1       0.81      0.82      0.81    107151\n\n    accuracy                           0.86    290014\n   macro avg       0.85      0.85      0.85    290014\nweighted avg       0.86      0.86      0.86    290014\n\n\n\n\nRandom Forest\n==================================================\nConfusion Matrix ::-\n[[165178  17685]\n [ 15173  91978]]\n-------------------------------------------------- \n\nAccuracy :: 0.8867020212817313\n\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91    182863\n           1       0.84      0.86      0.85    107151\n\n    accuracy                           0.89    290014\n   macro avg       0.88      0.88      0.88    290014\nweighted avg       0.89      0.89      0.89    290014\n\n\n\n\nK-Neighbors\n==================================================\nConfusion Matrix ::-\n[[158818  24045]\n [ 39627  67524]]\n-------------------------------------------------- \n\nAccuracy :: 0.7804519781803637\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.87      0.83    182863\n           1       0.74      0.63      0.68    107151\n\n    accuracy                           0.78    290014\n   macro avg       0.77      0.75      0.76    290014\nweighted avg       0.78      0.78      0.78    290014\n\n\n\n\n\n\n\ndef eval_gs(gs, output=\"best_estimator\"):\n    if output == \"best_estimator\":\n        return gs.best_estimator_\n    elif output == \"best_param\":\n        return gs.best_params_\n    elif output == \"scores_table\":\n        cv_res = gs.cv_results_\n        \n        f_df = pd.DataFrame(cv_res[\"params\"])\n        f_df[\"mean_test_score\"] = cv_res[\"mean_test_score\"]\n        f_df[\"rank_test_score\"] = cv_res[\"rank_test_score\"]\n        f_df[\"mean_train_score\"] = cv_res[\"mean_train_score\"]\n        return f_df.sort_values(by=\"rank_test_score\", ascending=True)\n    \n    elif output == \"feature_importance\":\n        feature_importances = gs.best_estimator_.feature_importances_\n        feat_imp = pd.DataFrame(sorted(zip(feature_names, feature_importances), reverse=True), columns = [\"importance_score\", \"Feature\"])\n        return feat_imp.sort_values(by = \"Feature\", ascending=False)\n    else:\n        raise ValueError(\"`output` variable was given a wrong value.\")\n\n\nparam_grid = {\"n_estimators\": [100, 200, 300], \"max_leaf_nodes\": [10, 16], 'max_features':[3, 4]}\n\ngrid_search = GridSearchCV(rf_class, param_grid, cv=4, n_jobs=-1, return_train_score=True)\n\ngrid_search.fit(X, y)\n\nGridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=11),\n             n_jobs=-1,\n             param_grid={'max_features': [3, 4], 'max_leaf_nodes': [10, 16],\n                         'n_estimators': [100, 200, 300]},\n             return_train_score=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=11),\n             n_jobs=-1,\n             param_grid={'max_features': [3, 4], 'max_leaf_nodes': [10, 16],\n                         'n_estimators': [100, 200, 300]},\n             return_train_score=True)estimator: RandomForestClassifierRandomForestClassifier(n_jobs=-1, random_state=11)RandomForestClassifierRandomForestClassifier(n_jobs=-1, random_state=11)\n\n\n\neval_gs(grid_search)\n\nRandomForestClassifier(max_features=4, max_leaf_nodes=16, n_jobs=-1,\n                       random_state=11)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_features=4, max_leaf_nodes=16, n_jobs=-1,\n                       random_state=11)\n\n\n\neval_gs(grid_search, \"best_param\")\n\n{'max_features': 4, 'max_leaf_nodes': 16, 'n_estimators': 100}\n\n\n\neval_gs(grid_search, \"scores_table\")\n\n\n\n\n\n  \n    \n      \n      max_features\n      max_leaf_nodes\n      n_estimators\n      mean_test_score\n      rank_test_score\n      mean_train_score\n    \n  \n  \n    \n      9\n      4\n      16\n      100\n      0.835939\n      1\n      0.846201\n    \n    \n      10\n      4\n      16\n      200\n      0.834090\n      2\n      0.845402\n    \n    \n      11\n      4\n      16\n      300\n      0.831949\n      3\n      0.843678\n    \n    \n      3\n      3\n      16\n      100\n      0.809878\n      4\n      0.818747\n    \n    \n      4\n      3\n      16\n      200\n      0.807188\n      5\n      0.817267\n    \n    \n      5\n      3\n      16\n      300\n      0.807185\n      6\n      0.816305\n    \n    \n      6\n      4\n      10\n      100\n      0.805216\n      7\n      0.812193\n    \n    \n      7\n      4\n      10\n      200\n      0.797896\n      8\n      0.805109\n    \n    \n      8\n      4\n      10\n      300\n      0.797492\n      9\n      0.805243\n    \n    \n      0\n      3\n      10\n      100\n      0.781183\n      10\n      0.787738\n    \n    \n      2\n      3\n      10\n      300\n      0.777797\n      11\n      0.783745\n    \n    \n      1\n      3\n      10\n      200\n      0.777648\n      12\n      0.784164\n    \n  \n\n\n\n\n\nft_imp = eval_gs(grid_search, \"feature_importance\")\nft_imp\n\n\n\n\n\n  \n    \n      \n      importance_score\n      Feature\n    \n  \n  \n    \n      1\n      Sensor2_PM2.5\n      0.512644\n    \n    \n      2\n      Sensor1_PM2.5\n      0.250991\n    \n    \n      3\n      S2_AQI\n      0.138374\n    \n    \n      4\n      S1_AQI\n      0.049779\n    \n    \n      0\n      Temperature\n      0.028415\n    \n    \n      5\n      Relative_Humidity\n      0.013785\n    \n    \n      7\n      Day_Of_Year\n      0.005353\n    \n    \n      6\n      Hour\n      0.000660\n    \n  \n\n\n\n\n\n(\n    ggplot(ft_imp, aes(x=\"reorder(importance_score, Feature)\", y=\"Feature\")) +\n    geom_col() +\n    coord_flip() +\n    labs(x=\"\", y=\"\", title=\"Feature Importance\") +\n    theme_light() +\n    theme(plot_title= element_text(color=\"#8F8F8F\", ha=\"right\"))\n)\n\n\n\n\n<ggplot: (80879219697)>\n\n\n\n\n\n\nAll missing values will be imputed with their respective median value and all other feature transformation done on the train set will be used on the test set.\n\nord_test = test.sort_values(by=\"Datetime\").reset_index(drop=True)\n\nadd_df = cfun.add_attributes(ord_test, drop_nan_value=False, fill_nan_value=True)\n\ntest_c = add_df.fill_missing_value(fill_fun = \"median\")\ntest_c = add_df.add_air_quality_index()\ntest_c = add_df.add_period_variables(hour=True, dayofyear=True)\ntest_c = test_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\ntest_c = full_pipeline.transform(test_c)\n\n\nfinal_model = grid_search.best_estimator_\n\nfinal_prediction = final_model.predict(test_c)\n\n\naccuracy_score(samplesubmission[\"Offset_fault\"], final_prediction)\n\n0.7908621948634197\n\n\n\nconfusion_matrix(samplesubmission[\"Offset_fault\"], final_prediction)\n\narray([[100725,  26636],\n       [     0,      0]], dtype=int64)\n\n\n\nprint(classification_report(samplesubmission[\"Offset_fault\"], final_prediction))\n\n              precision    recall  f1-score   support\n\n           0       1.00      0.79      0.88    127361\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.79    127361\n   macro avg       0.50      0.40      0.44    127361\nweighted avg       1.00      0.79      0.88    127361\n\n\n\nThe test set seem to have an unusual task of predicting just one class which was the time the PM sensors where considered to have no offset faults. That been said, the model only detect that there were no fault in the sensor signal 79% of the time. Given that there are only 0s i.e non offset sensors we have a percision of 100%.\n\n\n\nimport pickle\n\n# Save Models\nwith open(\"final_pm2.5_sensor_model.pkl\", \"wb\") as f:\n    pickle.dump(final_model, f)\n\n\n\n\n\ndef make_predictions(model_file_path, new_data=None, data_file_path=None):\n    \"\"\"\n    param: model_file_path: The file path to the pickle serialized file.\n    param: new_data: The new set of records.\n    param: data_file_path : The file path to the new set of records.\n\n    return: pandas serise with predicted values.\n    \"\"\"\n\n    # data transformation\n    from function import add_attributes\n    from pandas import Series\n\n    if new_data is not None:\n        mdl_data = new_data\n    \n    if data_file_path is not None:\n        mdl_data = data_file_path\n\n    ord_rec = mdl_data.sort_values(by=\"Datetime\").reset_index(drop=True)\n\n    add_df = add_attributes(ord_rec, drop_nan_value=False, fill_nan_value=True)\n\n    rec_c = add_df.fill_missing_value(fill_fun = \"median\")\n    rec_c = add_df.add_air_quality_index()\n    rec_c = add_df.add_period_variables(hour=True, dayofyear=True)\n    rec_c = rec_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\n    rec_c = full_pipeline.transform(rec_c)\n\n    # Load model\n    with open(model_file_path, \"rb\") as f:\n        model = pickle.load(f)\n    \n    # Generate predictions\n    y_preds = model.predict(rec_c)\n\n    # keep predictions in a pandas series\n    y_preds = Series(y_preds, index=ord_rec[\"ID\"], name=\"pm2.5_sensor_offsets\")\n\n    return y_preds"
  },
  {
    "objectID": "model_page.html",
    "href": "model_page.html",
    "title": "Sensor Offset Prediction",
    "section": "",
    "text": "Feature Engineering\nFor the training set all missing values will be removed from the data.\nAdditional variables such as an ordinal air quality index (as integer) for both sensors will be added to the training set.\nAlso the hour and day of the year will be extracted from the datetime variable after which the datetime variable will be dropped with the Id variable as they are both features with high cardinality.\n\nord_train = train.sort_values(by=\"Datetime\")\n\nadd_df = cfun.add_attributes(ord_train, drop_nan_value=True, fill_nan_value=False)\n\ntrain_c = add_df.drop_missing_value()\ntrain_c = add_df.add_air_quality_index()\ntrain_c = add_df.add_period_variables(hour=True, dayofyear=True)\ntrain_c = train_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\ntrain_c.info()\n\nC:\\Users\\AYOMIDE\\vs-python\\PM_ML_project\\function.py:237: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 290014 entries, 116880 to 226302\nData columns (total 9 columns):\n #   Column             Non-Null Count   Dtype  \n---  ------             --------------   -----  \n 0   Sensor1_PM2.5      290014 non-null  float64\n 1   Sensor2_PM2.5      290014 non-null  float64\n 2   Temperature        290014 non-null  float64\n 3   Relative_Humidity  290014 non-null  float64\n 4   Offset_fault       290014 non-null  int64  \n 5   S1_AQI             290014 non-null  int64  \n 6   S2_AQI             290014 non-null  int64  \n 7   Hour               290014 non-null  int64  \n 8   Day_Of_Year        290014 non-null  int64  \ndtypes: float64(4), int64(5)\nmemory usage: 22.1 MB\n\n\n\nSeparating the label for the predictors.\n\noutcome = \"Offset_fault\"\nX = train_c.drop(outcome, axis = 1)\ny = train_c[outcome]\n\nfeature_names = list(train_c.drop(outcome, axis = 1).columns)\n\n\n\nScale all numeric features\n\nnum_features = list(X.select_dtypes(\"number\").columns)\nnum_pipeline = Pipeline([\n    (\"std_scaler\", StandardScaler())\n])\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_features)\n])\n\nX = full_pipeline.fit_transform(X)\n\nX\n\narray([[-1.10957703, -1.01101351,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       [-1.08300205, -0.94242651,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       [-1.20189013, -1.22443398,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       ...,\n       [ 0.11881666,  0.48919661, -1.67174045, ..., -0.52823302,\n        -0.62421669, -1.84915195],\n       [ 0.27721755,  0.2761243 , -1.67174045, ..., -0.52823302,\n        -0.62421669, -1.84915195],\n       [-0.01650596, -0.22243706, -1.67174045, ...,  0.56632168,\n        -0.62421669, -1.84915195]])\n\n\n\n\nInital Selected Models\nMultiple models will be used to _see the best that generalize well on the validation set.\n\nlog_reg = LogisticRegression(random_state=11)\ndt_class = DecisionTreeClassifier(random_state=11)\nrf_class = RandomForestClassifier(random_state=11, n_jobs=-1)\nknn_class = KNeighborsClassifier(n_jobs=-1)\n\nmodel = [log_reg, dt_class, rf_class, knn_class]\nmodel_names = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"K-Neighbors\"]\n\n\n\nCross Validation\n\ndef cross_validation(model, x=X, y=y, model_name=\"model\", cv=5):\n    y_pred = cross_val_predict(model, x, y, cv=cv, n_jobs=-1) \n        \n    print(f\"{model_name}\\n{'='*50}\")\n    \n    print(f\"Confusion Matrix ::-\\n{confusion_matrix(y, y_pred)}\")\n    print(50*\"-\",\"\\n\")\n    print(f\"Accuracy :: {accuracy_score(y, y_pred)}\\n\")\n    print(classification_report(y, y_pred))\n\nFor better model performance evaluation the training set will be divided into a smaller training set and a validation set (default will be 5 splits).\n\nfor mdl, mdl_name in zip(model, model_names):\n    cross_validation(mdl, model_name=mdl_name)\n    print(\"\\n\\n\")\n\nLogistic Regression\n==================================================\n\n\nConfusion Matrix ::-\n[[171446  11417]\n [ 25463  81688]]\n-------------------------------------------------- \n\nAccuracy :: 0.8728337252684353\n\n\n\n              precision    recall  f1-score   support\n\n           0       0.87      0.94      0.90    182863\n           1       0.88      0.76      0.82    107151\n\n    accuracy                           0.87    290014\n   macro avg       0.87      0.85      0.86    290014\nweighted avg       0.87      0.87      0.87    290014\n\n\n\n\n\n\nDecision Tree\n==================================================\nConfusion Matrix ::-\n[[162400  20463]\n [ 19569  87582]]\n-------------------------------------------------- \n\nAccuracy :: 0.8619652844345446\n\n\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89    182863\n           1       0.81      0.82      0.81    107151\n\n    accuracy                           0.86    290014\n   macro avg       0.85      0.85      0.85    290014\nweighted avg       0.86      0.86      0.86    290014\n\n\n\n\n\n\nRandom Forest\n==================================================\nConfusion Matrix ::-\n[[165178  17685]\n [ 15173  91978]]\n-------------------------------------------------- \n\nAccuracy :: 0.8867020212817313\n\n\n\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91    182863\n           1       0.84      0.86      0.85    107151\n\n    accuracy                           0.89    290014\n   macro avg       0.88      0.88      0.88    290014\nweighted avg       0.89      0.89      0.89    290014\n\n\n\n\n\n\nK-Neighbors\n==================================================\nConfusion Matrix ::-\n[[158818  24045]\n [ 39627  67524]]\n-------------------------------------------------- \n\nAccuracy :: 0.7804519781803637\n\n\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.87      0.83    182863\n           1       0.74      0.63      0.68    107151\n\n    accuracy                           0.78    290014\n   macro avg       0.77      0.75      0.76    290014\nweighted avg       0.78      0.78      0.78    290014\n\n\n\n\n\n\nOut of all the inital selected models, The Random Forest model have the best performance when we look at it accuracy score in predicting sensor device signal offsets. The model also looks promising in generalizing well on other data.\n\ndef eval_gs(gs, output=\"best_estimator\"):\n    if output == \"best_estimator\":\n        return gs.best_estimator_\n    elif output == \"best_param\":\n        return gs.best_params_\n    elif output == \"scores_table\":\n        cv_res = gs.cv_results_\n        \n        f_df = pd.DataFrame(cv_res[\"params\"])\n        f_df[\"mean_test_score\"] = cv_res[\"mean_test_score\"]\n        f_df[\"rank_test_score\"] = cv_res[\"rank_test_score\"]\n        f_df[\"mean_train_score\"] = cv_res[\"mean_train_score\"]\n        return f_df.sort_values(by=\"rank_test_score\", ascending=True)\n    \n    elif output == \"feature_importance\":\n        feature_importances = grid_search.best_estimator_.feature_importances_\n        feat_imp = pd.DataFrame(sorted(zip(feature_names, feature_importances), reverse=True), columns = [\"importance_score\", \"Feature\"])\n        return feat_imp.sort_values(by = \"Feature\", ascending=False)\n    else:\n        raise ValueError(\"`output` variable was given a wrong value.\")\n\n\n\nHyperparameter Tuning\nUsing multiple random forest parameters to train the model on the data, in oreder to get the best combination of hyperparameter values.\n\nparam_grid = {\"n_estimators\": [100, 200, 300], \"max_leaf_nodes\": [10, 16], 'max_features':[3, 4]}\n\ngrid_search = GridSearchCV(rf_class, param_grid, cv=4, n_jobs=-1, return_train_score=True)\n\ngrid_search.fit(X, y)\n\nGridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=11),\n             n_jobs=-1,\n             param_grid={'max_features': [3, 4], 'max_leaf_nodes': [10, 16],\n                         'n_estimators': [100, 200, 300]},\n             return_train_score=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=11),\n             n_jobs=-1,\n             param_grid={'max_features': [3, 4], 'max_leaf_nodes': [10, 16],\n                         'n_estimators': [100, 200, 300]},\n             return_train_score=True)estimator: RandomForestClassifierRandomForestClassifier(n_jobs=-1, random_state=11)RandomForestClassifierRandomForestClassifier(n_jobs=-1, random_state=11)\n\n\n\nBest Estimators\n\neval_gs(grid_search)\n\nRandomForestClassifier(max_features=4, max_leaf_nodes=16, n_jobs=-1,\n                       random_state=11)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_features=4, max_leaf_nodes=16, n_jobs=-1,\n                       random_state=11)\n\n\n\neval_gs(grid_search, \"best_param\")\n\n{'max_features': 4, 'max_leaf_nodes': 16, 'n_estimators': 100}\n\n\n\neval_gs(grid_search, \"scores_table\")\n\n\n\n\n\n  \n    \n      \n      max_features\n      max_leaf_nodes\n      n_estimators\n      mean_test_score\n      rank_test_score\n      mean_train_score\n    \n  \n  \n    \n      9\n      4\n      16\n      100\n      0.835939\n      1\n      0.846201\n    \n    \n      10\n      4\n      16\n      200\n      0.834090\n      2\n      0.845402\n    \n    \n      11\n      4\n      16\n      300\n      0.831949\n      3\n      0.843678\n    \n    \n      3\n      3\n      16\n      100\n      0.809878\n      4\n      0.818747\n    \n    \n      4\n      3\n      16\n      200\n      0.807188\n      5\n      0.817267\n    \n    \n      5\n      3\n      16\n      300\n      0.807185\n      6\n      0.816305\n    \n    \n      6\n      4\n      10\n      100\n      0.805216\n      7\n      0.812193\n    \n    \n      7\n      4\n      10\n      200\n      0.797896\n      8\n      0.805109\n    \n    \n      8\n      4\n      10\n      300\n      0.797492\n      9\n      0.805243\n    \n    \n      0\n      3\n      10\n      100\n      0.781183\n      10\n      0.787738\n    \n    \n      2\n      3\n      10\n      300\n      0.777797\n      11\n      0.783745\n    \n    \n      1\n      3\n      10\n      200\n      0.777648\n      12\n      0.784164\n    \n  \n\n\n\n\n\n\nFeature Importance\nFinding the relative importance of each feature for making accurate predictions.\n\nft_imp = eval_gs(grid_search, \"feature_importance\")\nft_imp\n\n\n\n\n\n  \n    \n      \n      importance_score\n      Feature\n    \n  \n  \n    \n      1\n      Sensor2_PM2.5\n      0.512644\n    \n    \n      2\n      Sensor1_PM2.5\n      0.250991\n    \n    \n      3\n      S2_AQI\n      0.138374\n    \n    \n      4\n      S1_AQI\n      0.049779\n    \n    \n      0\n      Temperature\n      0.028415\n    \n    \n      5\n      Relative_Humidity\n      0.013785\n    \n    \n      7\n      Day_Of_Year\n      0.005353\n    \n    \n      6\n      Hour\n      0.000660\n    \n  \n\n\n\n\n\n(\n    ggplot(ft_imp, aes(x=\"reorder(importance_score, Feature)\", y=\"Feature\")) +\n    geom_col(fill=\"#788BFF\") +\n    coord_flip() +\n    labs(x=\"\", y=\"\", title=\"Feature Importance\") +\n    theme_light() +\n    theme(plot_title= element_text(color=\"#8F8F8F\"))\n)\n\n\n\n\n<ggplot: (101708896235)>\n\n\n\n\n\n\nEngineering The Test Set\nAll missing values will be imputed with their respective median value and all other feature transformation done on the train set will be used on the test set.\n\ntest = pd.read_csv('data/test.csv', parse_dates = ['Datetime'])\n\nord_test = test.sort_values(by=\"Datetime\").reset_index(drop=True)\n\nadd_df = cfun.add_attributes(ord_test, drop_nan_value=False, fill_nan_value=True)\n\ntest_c = add_df.fill_missing_value(fill_fun = \"median\")\ntest_c = add_df.add_air_quality_index()\ntest_c = add_df.add_period_variables(hour=True, dayofyear=True)\ntest_c = test_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\ntest_c = full_pipeline.transform(test_c)\n\nC:\\Users\\AYOMIDE\\vs-python\\PM_ML_project\\function.py:237: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n\n\n\nfinal_model = grid_search.best_estimator_\n\nfinal_prediction = final_model.predict(test_c)\n\n\nsamplesubmission = pd.read_csv('data/SampleSubmission.csv')\n\n\naccuracy_score(samplesubmission[\"Offset_fault\"], final_prediction)\n\n0.7908621948634197\n\n\n\nconfusion_matrix(samplesubmission[\"Offset_fault\"], final_prediction)\n\narray([[100725,  26636],\n       [     0,      0]], dtype=int64)\n\n\n\nprint(classification_report(samplesubmission[\"Offset_fault\"], final_prediction))\n\n              precision    recall  f1-score   support\n\n           0       1.00      0.79      0.88    127361\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.79    127361\n   macro avg       0.50      0.40      0.44    127361\nweighted avg       1.00      0.79      0.88    127361\n\n\n\nThe test set seems to have an unusual task of predicting just one class which was the time the PM sensors where considered to have no offset faults. That been said, the model only detect that there were no fault in the sensor signals 79% of the time. Given that there are only 0s i.e non offset sensor signals we have a percision of 100%.\n\nSaving Fitted Model\n\nimport pickle \n\nwith open(\"pm2.5_sensor_offset.pkl\", \"wb\") as f:\n    pickle.dump(final_model, f)\n\n\nFunction to easily make future predictions\n\ndef make_predictions(data_file_path, model_file_path):\n    \"\"\"\n    param: data_file_path : The file path to the new set of records.\n    param: model_file_path: The file path to the pickle serialized file.\n\n    return: pandas serise with predicted values.\n    \"\"\"\n\n    # data transformation\n    from function import add_attributes\n    from pandas import Series\n    ord_rec = test.sort_values(by=\"Datetime\").reset_index(drop=True)\n\n    add_df = add_attributes(ord_rec, drop_nan_value=False, fill_nan_value=True)\n\n    rec_c = add_df.fill_missing_value(fill_fun = \"median\")\n    rec_c = add_df.add_air_quality_index()\n    rec_c = add_df.add_period_variables(hour=True, dayofyear=True)\n    rec_c = rec_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\n    rec_c = full_pipeline.transform(rec_c)\n\n    # Load model\n    with open(model_file_path, \"rb\") as f:\n        model = pickle.load(f)\n    \n    # Generate predictions\n    y_preds = model.predict(rec_c)\n\n    # keep predictions in a pandas series\n    y_preds = Series(y_preds, index=ord_rec, name=\"pm2.5_sensor_offsets\")\n\n    return y_preds"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Akinwande Ayomide",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     Github\n  \n  \n    \n     Linkedin\n  \n\n      \nA strategic data analyst with a (passion) for developing (operational process) that (solves) business problems, improves business efficiency and delivering actionable insights using (various) analytical tools.\n\n\nAdekunle Ajasin University Akungba, Ondo State | Msc in Banking & Finance | Sept 2015 - Jan 2019\n\n\n\n\n\n\n\n\n\n\n\nPM2.5 sensor device offset Prediction.\n\n\nHospitality Management Dashboard.\n\n\nSegmentation Analysis Applications.\n\n\nMarket Basket Analysis Application."
  }
]