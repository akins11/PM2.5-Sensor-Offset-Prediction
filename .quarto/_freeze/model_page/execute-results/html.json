{
  "hash": "e034de3d91db1a1ceaf2635195f4f418",
  "result": {
    "markdown": "---\ntitle: Sensor Offset Prediction\n---\n\n### Libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold, cross_validate, cross_val_score, cross_val_predict  # train_test_split,\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import KNNImputer\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score\n```\n:::\n\n\n\n\n### Feature Engineering\nFor the training set all missing values will be removed from the data.  \nAdditional variables such as an ordinal air quality index (as integer) for both sensors will be added to the training set.  \nAlso the hour and day of the year will be extracted from the datetime variable after which the datetime variable will be dropped with the Id variable as they are both features with high cardinality.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nord_train = train.sort_values(by=\"Datetime\")\n\nadd_df = cfun.add_attributes(ord_train, drop_nan_value=True, fill_nan_value=False)\n\ntrain_c = add_df.drop_missing_value()\ntrain_c = add_df.add_air_quality_index()\ntrain_c = add_df.add_period_variables(hour=True, dayofyear=True)\ntrain_c = train_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\ntrain_c.info()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\AYOMIDE\\vs-python\\PM_ML_project\\function.py:237: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 290014 entries, 116880 to 226302\nData columns (total 9 columns):\n #   Column             Non-Null Count   Dtype  \n---  ------             --------------   -----  \n 0   Sensor1_PM2.5      290014 non-null  float64\n 1   Sensor2_PM2.5      290014 non-null  float64\n 2   Temperature        290014 non-null  float64\n 3   Relative_Humidity  290014 non-null  float64\n 4   Offset_fault       290014 non-null  int64  \n 5   S1_AQI             290014 non-null  int64  \n 6   S2_AQI             290014 non-null  int64  \n 7   Hour               290014 non-null  int64  \n 8   Day_Of_Year        290014 non-null  int64  \ndtypes: float64(4), int64(5)\nmemory usage: 22.1 MB\n```\n:::\n:::\n\n\n##### Separating the label for the predictors.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\noutcome = \"Offset_fault\"\nX = train_c.drop(outcome, axis = 1)\ny = train_c[outcome]\n\nfeature_names = list(train_c.drop(outcome, axis = 1).columns)\n```\n:::\n\n\n##### Scale all numeric features\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nnum_features = list(X.select_dtypes(\"number\").columns)\nnum_pipeline = Pipeline([\n    (\"std_scaler\", StandardScaler())\n])\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_features)\n])\n\nX = full_pipeline.fit_transform(X)\n\nX\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\narray([[-1.10957703, -1.01101351,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       [-1.08300205, -0.94242651,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       [-1.20189013, -1.22443398,  1.71196075, ...,  1.66087637,\n         0.66730492,  0.20484599],\n       ...,\n       [ 0.11881666,  0.48919661, -1.67174045, ..., -0.52823302,\n        -0.62421669, -1.84915195],\n       [ 0.27721755,  0.2761243 , -1.67174045, ..., -0.52823302,\n        -0.62421669, -1.84915195],\n       [-0.01650596, -0.22243706, -1.67174045, ...,  0.56632168,\n        -0.62421669, -1.84915195]])\n```\n:::\n:::\n\n\n#### Inital Selected Models\nMultiple models will be used to _see the best that generalize well on the validation set.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nlog_reg = LogisticRegression(random_state=11)\ndt_class = DecisionTreeClassifier(random_state=11)\nrf_class = RandomForestClassifier(random_state=11, n_jobs=-1)\nknn_class = KNeighborsClassifier(n_jobs=-1)\n\nmodel = [log_reg, dt_class, rf_class, knn_class]\nmodel_names = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"K-Neighbors\"]\n```\n:::\n\n\n#### Cross Validation\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef cross_validation(model, x=X, y=y, model_name=\"model\", cv=5):\n    y_pred = cross_val_predict(model, x, y, cv=cv, n_jobs=-1) \n        \n    print(f\"{model_name}\\n{'='*50}\")\n    \n    print(f\"Confusion Matrix ::-\\n{confusion_matrix(y, y_pred)}\")\n    print(50*\"-\",\"\\n\")\n    print(f\"Accuracy :: {accuracy_score(y, y_pred)}\\n\")\n    print(classification_report(y, y_pred))\n```\n:::\n\n\nFor better model performance evaluation the training set will be divided into a smaller training set and a validation set (default will be 5 splits).\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfor mdl, mdl_name in zip(model, model_names):\n    cross_validation(mdl, model_name=mdl_name)\n    print(\"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression\n==================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix ::-\n[[171446  11417]\n [ 25463  81688]]\n-------------------------------------------------- \n\nAccuracy :: 0.8728337252684353\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.87      0.94      0.90    182863\n           1       0.88      0.76      0.82    107151\n\n    accuracy                           0.87    290014\n   macro avg       0.87      0.85      0.86    290014\nweighted avg       0.87      0.87      0.87    290014\n\n\n\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nDecision Tree\n==================================================\nConfusion Matrix ::-\n[[162400  20463]\n [ 19569  87582]]\n-------------------------------------------------- \n\nAccuracy :: 0.8619652844345446\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.89      0.89      0.89    182863\n           1       0.81      0.82      0.81    107151\n\n    accuracy                           0.86    290014\n   macro avg       0.85      0.85      0.85    290014\nweighted avg       0.86      0.86      0.86    290014\n\n\n\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom Forest\n==================================================\nConfusion Matrix ::-\n[[165178  17685]\n [ 15173  91978]]\n-------------------------------------------------- \n\nAccuracy :: 0.8867020212817313\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.92      0.90      0.91    182863\n           1       0.84      0.86      0.85    107151\n\n    accuracy                           0.89    290014\n   macro avg       0.88      0.88      0.88    290014\nweighted avg       0.89      0.89      0.89    290014\n\n\n\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nK-Neighbors\n==================================================\nConfusion Matrix ::-\n[[158818  24045]\n [ 39627  67524]]\n-------------------------------------------------- \n\nAccuracy :: 0.7804519781803637\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.80      0.87      0.83    182863\n           1       0.74      0.63      0.68    107151\n\n    accuracy                           0.78    290014\n   macro avg       0.77      0.75      0.76    290014\nweighted avg       0.78      0.78      0.78    290014\n\n\n\n\n```\n:::\n:::\n\n\nOut of all the inital selected models, The Random Forest model have the best performance when we look at it accuracy score in predicting sensor device signal offsets. The model also looks promising in generalizing well on other data.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef eval_gs(gs, output=\"best_estimator\"):\n    if output == \"best_estimator\":\n        return gs.best_estimator_\n    elif output == \"best_param\":\n        return gs.best_params_\n    elif output == \"scores_table\":\n        cv_res = gs.cv_results_\n        \n        f_df = pd.DataFrame(cv_res[\"params\"])\n        f_df[\"mean_test_score\"] = cv_res[\"mean_test_score\"]\n        f_df[\"rank_test_score\"] = cv_res[\"rank_test_score\"]\n        f_df[\"mean_train_score\"] = cv_res[\"mean_train_score\"]\n        return f_df.sort_values(by=\"rank_test_score\", ascending=True)\n    \n    elif output == \"feature_importance\":\n        feature_importances = grid_search.best_estimator_.feature_importances_\n        feat_imp = pd.DataFrame(sorted(zip(feature_names, feature_importances), reverse=True), columns = [\"importance_score\", \"Feature\"])\n        return feat_imp.sort_values(by = \"Feature\", ascending=False)\n    else:\n        raise ValueError(\"`output` variable was given a wrong value.\")\n```\n:::\n\n\n#### Hyperparameter Tuning\nUsing multiple random forest parameters to train the model on the data, in oreder to get the best combination of hyperparameter values.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nparam_grid = {\"n_estimators\": [100, 200, 300], \"max_leaf_nodes\": [10, 16], 'max_features':[3, 4]}\n\ngrid_search = GridSearchCV(rf_class, param_grid, cv=4, n_jobs=-1, return_train_score=True)\n\ngrid_search.fit(X, y)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=11),\n             n_jobs=-1,\n             param_grid={&#x27;max_features&#x27;: [3, 4], &#x27;max_leaf_nodes&#x27;: [10, 16],\n                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=11),\n             n_jobs=-1,\n             param_grid={&#x27;max_features&#x27;: [3, 4], &#x27;max_leaf_nodes&#x27;: [10, 16],\n                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=11)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=11)</pre></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\n##### Best Estimators\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\neval_gs(grid_search)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=4, max_leaf_nodes=16, n_jobs=-1,\n                       random_state=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=4, max_leaf_nodes=16, n_jobs=-1,\n                       random_state=11)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\neval_gs(grid_search, \"best_param\")\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n{'max_features': 4, 'max_leaf_nodes': 16, 'n_estimators': 100}\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\neval_gs(grid_search, \"scores_table\")\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max_features</th>\n      <th>max_leaf_nodes</th>\n      <th>n_estimators</th>\n      <th>mean_test_score</th>\n      <th>rank_test_score</th>\n      <th>mean_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>16</td>\n      <td>100</td>\n      <td>0.835939</td>\n      <td>1</td>\n      <td>0.846201</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4</td>\n      <td>16</td>\n      <td>200</td>\n      <td>0.834090</td>\n      <td>2</td>\n      <td>0.845402</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4</td>\n      <td>16</td>\n      <td>300</td>\n      <td>0.831949</td>\n      <td>3</td>\n      <td>0.843678</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>16</td>\n      <td>100</td>\n      <td>0.809878</td>\n      <td>4</td>\n      <td>0.818747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>16</td>\n      <td>200</td>\n      <td>0.807188</td>\n      <td>5</td>\n      <td>0.817267</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>16</td>\n      <td>300</td>\n      <td>0.807185</td>\n      <td>6</td>\n      <td>0.816305</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4</td>\n      <td>10</td>\n      <td>100</td>\n      <td>0.805216</td>\n      <td>7</td>\n      <td>0.812193</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4</td>\n      <td>10</td>\n      <td>200</td>\n      <td>0.797896</td>\n      <td>8</td>\n      <td>0.805109</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>10</td>\n      <td>300</td>\n      <td>0.797492</td>\n      <td>9</td>\n      <td>0.805243</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>10</td>\n      <td>100</td>\n      <td>0.781183</td>\n      <td>10</td>\n      <td>0.787738</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>10</td>\n      <td>300</td>\n      <td>0.777797</td>\n      <td>11</td>\n      <td>0.783745</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>10</td>\n      <td>200</td>\n      <td>0.777648</td>\n      <td>12</td>\n      <td>0.784164</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n##### Feature Importance\nFinding the relative importance of each feature for making accurate predictions.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nft_imp = eval_gs(grid_search, \"feature_importance\")\nft_imp\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance_score</th>\n      <th>Feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Sensor2_PM2.5</td>\n      <td>0.512644</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sensor1_PM2.5</td>\n      <td>0.250991</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S2_AQI</td>\n      <td>0.138374</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>S1_AQI</td>\n      <td>0.049779</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Temperature</td>\n      <td>0.028415</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Relative_Humidity</td>\n      <td>0.013785</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Day_Of_Year</td>\n      <td>0.005353</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Hour</td>\n      <td>0.000660</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n(\n    ggplot(ft_imp, aes(x=\"reorder(importance_score, Feature)\", y=\"Feature\")) +\n    geom_col(fill=\"#788BFF\") +\n    coord_flip() +\n    labs(x=\"\", y=\"\", title=\"Feature Importance\") +\n    theme_light() +\n    theme(plot_title= element_text(color=\"#8F8F8F\"))\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](model_page_files/figure-html/cell-16-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n<ggplot: (101708896235)>\n```\n:::\n:::\n\n\n### Engineering The Test Set\nAll missing values will be imputed with their respective median value and all other feature transformation done on the train set will be used on the test set.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ntest = pd.read_csv('data/test.csv', parse_dates = ['Datetime'])\n\nord_test = test.sort_values(by=\"Datetime\").reset_index(drop=True)\n\nadd_df = cfun.add_attributes(ord_test, drop_nan_value=False, fill_nan_value=True)\n\ntest_c = add_df.fill_missing_value(fill_fun = \"median\")\ntest_c = add_df.add_air_quality_index()\ntest_c = add_df.add_period_variables(hour=True, dayofyear=True)\ntest_c = test_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\ntest_c = full_pipeline.transform(test_c)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\AYOMIDE\\vs-python\\PM_ML_project\\function.py:237: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfinal_model = grid_search.best_estimator_\n\nfinal_prediction = final_model.predict(test_c)\n```\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nsamplesubmission = pd.read_csv('data/SampleSubmission.csv')\n```\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\naccuracy_score(samplesubmission[\"Offset_fault\"], final_prediction)\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n0.7908621948634197\n```\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nconfusion_matrix(samplesubmission[\"Offset_fault\"], final_prediction)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\narray([[100725,  26636],\n       [     0,      0]], dtype=int64)\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nprint(classification_report(samplesubmission[\"Offset_fault\"], final_prediction))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       1.00      0.79      0.88    127361\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.79    127361\n   macro avg       0.50      0.40      0.44    127361\nweighted avg       1.00      0.79      0.88    127361\n\n```\n:::\n:::\n\n\nThe test set seems to have an unusual task of predicting just one class which was the time the PM sensors where considered to have no offset faults. That been said, the model only detect that there were no fault in the sensor signals 79% of the time. Given that there are only 0s i.e non offset sensor signals we have a percision of 100%.\n\n\n#### Saving Fitted Model\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nimport pickle \n\nwith open(\"pm2.5_sensor_offset.pkl\", \"wb\") as f:\n    pickle.dump(final_model, f)\n```\n:::\n\n\n##### Function to easily make future predictions\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ndef make_predictions(data_file_path, model_file_path):\n    \"\"\"\n    param: data_file_path : The file path to the new set of records.\n    param: model_file_path: The file path to the pickle serialized file.\n\n    return: pandas serise with predicted values.\n    \"\"\"\n\n    # data transformation\n    from function import add_attributes\n    from pandas import Series\n    ord_rec = test.sort_values(by=\"Datetime\").reset_index(drop=True)\n\n    add_df = add_attributes(ord_rec, drop_nan_value=False, fill_nan_value=True)\n\n    rec_c = add_df.fill_missing_value(fill_fun = \"median\")\n    rec_c = add_df.add_air_quality_index()\n    rec_c = add_df.add_period_variables(hour=True, dayofyear=True)\n    rec_c = rec_c.drop([\"ID\", \"Datetime\"], axis = 1)\n\n    rec_c = full_pipeline.transform(rec_c)\n\n    # Load model\n    with open(model_file_path, \"rb\") as f:\n        model = pickle.load(f)\n    \n    # Generate predictions\n    y_preds = model.predict(rec_c)\n\n    # keep predictions in a pandas series\n    y_preds = Series(y_preds, index=ord_rec, name=\"pm2.5_sensor_offsets\")\n\n    return y_preds\n```\n:::\n\n\n",
    "supporting": [
      "model_page_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}